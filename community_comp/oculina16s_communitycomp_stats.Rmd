---
title: "oculina16s_communitycomp"
output: html_document
date: '2022-06-08'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Setup

```{r packages composition}
library(rlang)
library(stringr)
library(dplyr)
library(stats)
library(ggpubr)
library(vegan)
library(cowplot)
library(tidyverse)
#library(MCMC.OTU)
#install.packages("remotes")
#remotes::install_github("Jtrachsel/funfuns")
library("funfuns")
#BiocManager::install("microbiome")
#remotes::install_github("r-lib/rlang")
library(microbiome)
```


Read in data

```{r read in data}
setwd("~/oculina/data")
samdf <- read.csv("~/oculina/data/oculina16s_sampledata_symdens.csv",header=TRUE)
load("~/oculina/data/taxa2.Rdata")
#load("ps.clean.Rdata")
load("~/oculina/data/ps.less_rev.Rdata")
#load("ps.rare.trim.Rdata")
#load("ps.trim.Rdata")
#ps.cleanest <- readRDS("phyloseq.cleanest.RDS")

```


Rename ASVs to be more informative

```{r rename ASVs}
tax <- as.data.frame(ps.less@tax_table@.Data)
tax.clean <- data.frame(row.names = row.names(tax),
                        Kingdom = str_replace(tax[,1], "D_0__",""),
                        Phylum = str_replace(tax[,2], "D_1__",""),
                        Class = str_replace(tax[,3], "D_2__",""),
                        Order = str_replace(tax[,4], "D_3__",""),
                        Family = str_replace(tax[,5], "D_4__",""),
                        Genus = str_replace(tax[,6], "D_5__",""),
                        Species = str_replace(tax[,7], "D_6__",""),
                        stringsAsFactors = FALSE)
tax.clean[is.na(tax.clean)] <- ""


for (i in 1:7){ tax.clean[,i] <- as.character(tax.clean[,i])}
####### Fill holes in the tax table
tax.clean[is.na(tax.clean)] <- ""
for (i in 1:nrow(tax.clean)){
  if (tax.clean[i,2] == ""){
    kingdom <- paste("Kingdom_", tax.clean[i,1], sep = "")
    tax.clean[i, 2:7] <- kingdom
  } else if (tax.clean[i,3] == ""){
    phylum <- paste("Phylum_", tax.clean[i,2], sep = "")
    tax.clean[i, 3:7] <- phylum
  } else if (tax.clean[i,4] == ""){
    class <- paste("Class_", tax.clean[i,3], sep = "")
    tax.clean[i, 4:7] <- class
  } else if (tax.clean[i,5] == ""){
    order <- paste("Order_", tax.clean[i,4], sep = "")
    tax.clean[i, 5:7] <- order
  } else if (tax.clean[i,6] == ""){
    family <- paste("Family_", tax.clean[i,5], sep = "")
    tax.clean[i, 6:7] <- family
  } else if (tax.clean[i,7] == ""){
    tax.clean$Species[i] <- paste("Genus",tax.clean$Genus[i], sep = "_")
  }
}

tax_table(ps.less) <- as.matrix(tax.clean)


```



### Stats

# Transform data using centered log ratio (makes data symmetric and linearly related)
```{r transform data using CLR}
#library(microbiome)
ps.less.clr <- transform(ps.less, 'clr') #otu table: no longer counts, but rather the dominance (or lack thereof) for each taxa relative to the geometric mean of all taxa on the logarithmic scale
# read more here: https://www.nicholas-ollberding.com/post/introduction-to-the-statistical-analysis-of-microbiome-data-in-r/
#basically, need to do CLR because microbiome data is compositional data and this is necessary in order to meet assumptions of methods below (Explains in link above and links within article to other papers); compositional data should be analyzed using euclidian instead of bray, I think


#load("~/oculina/data/ps.rare.rev.clr.Rdata")
#subset coral
ps.coral.clr <- subset_samples(ps.less.clr,type=="coral")
#ps.coral <- subset_samples(ps.less,type=="coral")


ord.coral.clr <- ordinate(ps.coral.clr, "RDA")
plot_scree(ord.coral.clr)+
  geom_bar(stat="identity",fill="blue")+
  labs(x = "\nAxis", y = "Proportion of Variance\n")


#Applying PCA to CLR-transformed data will give us Aitchison distance-based ordinatinon
#We can use PERMANOVA to test whether they cluster
```
```{r}
#seq.coral <- data.frame(otu_table(ps.coral))
#dist.coral <- vegdist(seq.coral)
#samdf.coral <- data.frame(sample_data(ps.coral))
#row.names(samdf.coral)==row.names(seq.coral)

ord.clr <- ordinate(ps.coral, "RDA")
plot_scree(ord.clr)+
  geom_bar(stat="identity",fill="blue")+
  labs(x = "\nAxis", y = "Proportion of Variance\n")

#Examine eigenvalues and % prop. variance explained
head(ord.clr$CA$eig)
sapply(ord.clr$CA$eig[1:5], function(x) x / sum(ord.clr$CA$eig))    

#"RDA without constraints is PCA…and we can generate the PCs using the phyloseq::ordinate function. A scree plot is then used to examine the proportion of total variation explained by each PC. Here we see that the first PC really stands out and then we have a gradual decline for the remaining components. You may hear people talk about looking for the “elbow” in the plot where the information plateaus to select the number of PCs to retain."

```
```{r adonis types}
seq.less <- data.frame(otu_table(ps.less.clr))
dist.less <- vegdist(seq.less, method="euclidian")
samdf.less <- data.frame(sample_data(ps.less.clr))
row.names(samdf.less)==row.names(seq.less)

adonis2(dist.less ~ type, data=samdf.less, permutations=999)
#         Df SumOfSqs      R2      F Pr(>F)    
#type      2    34137 0.11949 4.6139  0.001 ***
#Residual 68   251556 0.88051                  
#Total    70   285693 1.00000 

adonis2(dist.less ~ type*season, data=samdf.less, permutations=999)
#            Df SumOfSqs      R2      F Pr(>F)    
#type         2    34137 0.11949 4.8378  0.001 ***
#season       1     7553 0.02644 2.1409  0.001 ***
#type:season  2    14676 0.05137 2.0799  0.001 ***
#Residual    65   229326 0.80270                  
#Total       70   285693 1.00000    

adonis2(dist.less ~ type*site, data=samdf.less, permutations=999)
#          Df SumOfSqs      R2      F Pr(>F)    
#type       2    34137 0.11949 4.8287  0.001 ***
#site       2    10020 0.03507 1.4174  0.002 ** 
#type:site  4    22381 0.07834 1.5829  0.001 ***
#Residual  62   219155 0.76710                  
#Total     70   285693 1.00000  

adonis2(dist.less ~ type*season*site, data=samdf.less, permutations=999)


```

```{r stats for coral (clr-transformed)}
# need to do euclidian instead of bray for CLR transformed data...

seq.coral <- data.frame(otu_table(ps.coral.clr))
dist.coral <- vegdist(seq.coral, method="euclidian")
samdf.coral <- data.frame(sample_data(ps.coral.clr))
row.names(samdf.coral)==row.names(seq.coral)


adonis2(dist.coral ~ site, data=samdf.coral, permutations=999)
#         Df SumOfSqs      R2      F Pr(>F)    
#site      2     8045 0.06149 1.3758  0.001 ***
#Residual 42   122801 0.93851                  
#Total    44   130846 1.00000   

adonis2(dist.coral ~ season, data=samdf.coral, permutations=999) 
#         Df SumOfSqs      R2      F Pr(>F)    
#season    1     5253 0.04014 1.7984  0.001 ***
#Residual 43   125594 0.95986                  
#Total    44   130846 1.00000             

adonis2(dist.coral ~ symbstate, data=samdf.coral, permutations=999)
#          Df SumOfSqs      R2      F Pr(>F)
#symbstate  1     2930 0.02239 0.9849  0.524
#Residual  43   127916 0.97761              
#Total     44   130846 1.00000 

# will look at site and season as main effects as well as their interaction term
adonis2(dist.coral ~ site*season, data=samdf.coral, permutations=999)
#            Df SumOfSqs      R2      F Pr(>F)    
#site         2     8045 0.06149 1.4097  0.001 ***
#season       1     4518 0.03453 1.5834  0.001 ***
#site:season  1     4138 0.03163 1.4501  0.002 ** 
#Residual    40   114144 0.87235                  
#Total       44   130846 1.00000    


# site * symbstate
adonis2(dist.coral ~ site*symbstate, data=samdf.coral, permutations=999) #only site sig (***)

# season * symbstate
adonis2(dist.coral ~ season*symbstate, data=samdf.coral, permutations=999) #only season sig (***)

adonis2(dist.coral ~ season*symbstate*site, data=samdf.coral, permutations=999) 
#                      Df SumOfSqs      R2      F Pr(>F)    
#season                 1     5253 0.04014 1.8552  0.001 ***
#symbstate              1     2929 0.02239 1.0346  0.265    
#site                   2     7344 0.05613 1.2969  0.001 ***
#season:symbstate       1     2904 0.02220 1.0258  0.393    
#season:site            1     4129 0.03156 1.4585  0.002 ** 
#symbstate:site         2     5951 0.04548 1.0509  0.217    
#season:symbstate:site  1     3241 0.02477 1.1448  0.117    
#Residual              35    99094 0.75734                  
#Total                 44   130846 1.00000   
# try with just NR and RI just to check
ps.coral.noCL <- subset_samples(ps.coral,site %in% c("NR","RI"))
seq.coral.noCL <- data.frame(otu_table(ps.coral.noCL))
dist.coral.noCL <- vegdist(seq.coral.noCL, method="euclidian")
samdf.coral.noCL <- data.frame(sample_data(ps.coral.noCL))
row.names(samdf.coral.noCL)==row.names(seq.coral.noCL)
adonis2(dist.coral.noCL ~ symbstate, data=samdf.coral.noCL, permutations=999) #not sig

### BETADISPER ###
# If you have uneven variation in your data, adonis might not be effective -- should check for variation in dispersion using betadisper

# CORAL - SITE
bet.all <- betadisper(dist.coral,samdf.coral$site) #Betadisper calculates the average distance of group members to the group centroid in multivariate space (generated by a distance matrix). ANOVA/Permutest then tests whether distances are significantly different between groups.
bet.all
#Average distance to median:
#   CL    NR    RI 
#43.23 54.10 51.07 

#anova(bet.all)
plot(bet.all) 
permutest(bet.all, pairwise = TRUE, permutations = 999) #ns

# CORAL - SEASON
bet.all <- betadisper(dist.coral,samdf.coral$season)
plot(bet.all)
permutest(bet.all, pairwise = TRUE, permutations = 999) #ns

# CORAL - SYMB STATE
bet.all <- betadisper(dist.coral,samdf.coral$symbstate)
plot(bet.all)
permutest(bet.all, pairwise = TRUE, permutations = 999) #ns

# Excluding CL
bet.all <- betadisper(dist.coral.noCL,samdf.coral.noCL$symbstate)
plot(bet.all)
permutest(bet.all, pairwise = TRUE, permutations = 999) #ns

```



```{r plot heatmap}
ps.coral.pt <- prune_taxa(names(sort(taxa_sums(ps.coral),TRUE)[1:300]), ps.coral)
plot_heatmap(ps.coral.pt)


```


```{r bubble plot}
library("reshape2")
library("stringr")
library("ggplot2")
library("RColorBrewer")

#setwd("~/oculina_old/setup/tax")
OTU = read.table("ASVtable.txt", header=TRUE, sep="\t", row.names = 1)
RAtab <- sweep(OTU,1,rowSums(OTU),"/")
#write.csv(RAtab, "ASVtablePercent.csv") #uncomment this to write out your new ASV table
#row sums before
rowSums(OTU)
#check row sums after-- should be 1 for all samples
rowSums(RAtab)


```

